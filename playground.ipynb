{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame': 0, 'leds_glowing': 2},\n",
       " {'frame': 50, 'leds_glowing': 2},\n",
       " {'frame': 100, 'leds_glowing': 2},\n",
       " {'frame': 150, 'leds_glowing': 2},\n",
       " {'frame': 200, 'leds_glowing': 2},\n",
       " {'frame': 250, 'leds_glowing': 2},\n",
       " {'frame': 300, 'leds_glowing': 2},\n",
       " {'frame': 350, 'leds_glowing': 3},\n",
       " {'frame': 400, 'leds_glowing': 2},\n",
       " {'frame': 450, 'leds_glowing': 2},\n",
       " {'frame': 500, 'leds_glowing': 2},\n",
       " {'frame': 550, 'leds_glowing': 3},\n",
       " {'frame': 600, 'leds_glowing': 3},\n",
       " {'frame': 650, 'leds_glowing': 3},\n",
       " {'frame': 700, 'leds_glowing': 3},\n",
       " {'frame': 750, 'leds_glowing': 3},\n",
       " {'frame': 800, 'leds_glowing': 3},\n",
       " {'frame': 850, 'leds_glowing': 5},\n",
       " {'frame': 900, 'leds_glowing': 3},\n",
       " {'frame': 950, 'leds_glowing': 3},\n",
       " {'frame': 1000, 'leds_glowing': 4},\n",
       " {'frame': 1050, 'leds_glowing': 5},\n",
       " {'frame': 1100, 'leds_glowing': 5},\n",
       " {'frame': 1150, 'leds_glowing': 4},\n",
       " {'frame': 1200, 'leds_glowing': 6},\n",
       " {'frame': 1250, 'leds_glowing': 5},\n",
       " {'frame': 1300, 'leds_glowing': 4},\n",
       " {'frame': 1350, 'leds_glowing': 4},\n",
       " {'frame': 1400, 'leds_glowing': 4},\n",
       " {'frame': 1450, 'leds_glowing': 4},\n",
       " {'frame': 1500, 'leds_glowing': 5},\n",
       " {'frame': 1550, 'leds_glowing': 4},\n",
       " {'frame': 1600, 'leds_glowing': 4},\n",
       " {'frame': 1650, 'leds_glowing': 4},\n",
       " {'frame': 1700, 'leds_glowing': 4},\n",
       " {'frame': 1750, 'leds_glowing': 6},\n",
       " {'frame': 1800, 'leds_glowing': 5},\n",
       " {'frame': 1850, 'leds_glowing': 2},\n",
       " {'frame': 1900, 'leds_glowing': 2},\n",
       " {'frame': 1950, 'leds_glowing': 2}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def create_output_directories(base_dir, test_number):\n",
    "    test_dir = os.path.join(base_dir, f\"test_{test_number}\")\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "    return test_dir\n",
    "\n",
    "def save_images(image, image_name, test_dir):\n",
    "    image_path = os.path.join(test_dir, image_name)\n",
    "    cv2.imwrite(image_path, image)\n",
    "\n",
    "def count_glowing_leds(gray_image, threshold=200, debug=False, test_dir=None, frame_number=0):\n",
    "    # Simple threshold to identify glowing LEDs\n",
    "    _, binary_image = cv2.threshold(gray_image, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours of the glowing areas\n",
    "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if debug:\n",
    "        # Save and display grayscale image\n",
    "        gray_image_name = f\"frame_{frame_number}_grayscale.png\"\n",
    "        save_images(gray_image, gray_image_name, test_dir)\n",
    "        # cv2.imshow('Grayscale Image', gray_image)\n",
    "\n",
    "        # Save and display binary image\n",
    "        binary_image_name = f\"frame_{frame_number}_binary.png\"\n",
    "        save_images(binary_image, binary_image_name, test_dir)\n",
    "        # cv2.imshow('Binary Image', binary_image)\n",
    "\n",
    "        # Draw contours on the grayscale image and save/display it\n",
    "        contour_image = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2BGR)\n",
    "        cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "        contour_image_name = f\"frame_{frame_number}_contours.png\"\n",
    "        save_images(contour_image, contour_image_name, test_dir)\n",
    "        # cv2.imshow('Contour Image', contour_image)\n",
    "\n",
    "        # Wait for user input to close the image windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return len(contours)\n",
    "\n",
    "def process_video(video_path, samples_per_minute=24, threshold=200, debug=False):\n",
    "    # Create base output directory\n",
    "    base_dir = \"outputs\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "    # Determine test number by counting existing tests\n",
    "    existing_tests = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    test_number = len(existing_tests) + 1\n",
    "\n",
    "    # Create directory for this test run\n",
    "    test_dir = create_output_directories(base_dir, test_number)\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames / frame_rate\n",
    "\n",
    "    # Calculate the interval between frames to sample\n",
    "    sample_interval = int(frame_rate * (60 / samples_per_minute))\n",
    "\n",
    "    results = []\n",
    "    frame_number = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_number % sample_interval == 0:\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            led_count = count_glowing_leds(gray_frame, threshold, debug, test_dir, frame_number)\n",
    "            results.append({\n",
    "                'frame': frame_number,\n",
    "                'leds_glowing': led_count\n",
    "            })\n",
    "\n",
    "        frame_number += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    results_path = os.path.join(test_dir, 'leds_glowing_results.json')\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage with debugging enabled\n",
    "video_path = 'video/sample_2.avi'\n",
    "samples_per_minute = 24  # Change this value as needed\n",
    "threshold = 240  # Adjust the threshold based on the brightness of LEDs (default 200)\n",
    "process_video(video_path, samples_per_minute, threshold, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting video to contours video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour video saved as video/sample_2_contour.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def convert_video_to_contour_video(input_video_path, output_video_path, threshold=250):\n",
    "    # Open the input video\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Cannot open video {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply threshold to identify glowing LEDs (or other bright objects)\n",
    "        _, binary_image = cv2.threshold(gray_frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw contours on the original frame\n",
    "        contour_frame = frame.copy()\n",
    "        cv2.drawContours(contour_frame, contours, -1, (0, 255, 0), 2)  # Green contours\n",
    "\n",
    "        # Write the frame with contours to the output video\n",
    "        out.write(contour_frame)\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Contour video saved as {output_video_path}\")\n",
    "\n",
    "# Example usage\n",
    "input_video_path = 'video/sample_2.avi'  # Input video file path\n",
    "output_video_path = 'video/sample_2_contour.avi'  # Output video file path\n",
    "threshold = 240  # Adjust the threshold based on the brightness of the objects of interest\n",
    "\n",
    "convert_video_to_contour_video(input_video_path, output_video_path, threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
